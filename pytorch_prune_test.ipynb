{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zache1/anaconda3/envs/pyt/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "from pytorch_resnet_cifar10 import resnet\n",
    "import model_utils\n",
    "import pruning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CIFAR10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# perform the same transform on all the data\n",
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.ToTensor(), # scale the data between 0..1\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # normalize the data\n",
    "\n",
    "# get the cifar10 data\n",
    "data_train = tv.datasets.CIFAR10(root=\"data/CIFAR10/train\", train=True, download=True, transform=transform)\n",
    "data_test = tv.datasets.CIFAR10(root=\"data/CIFAR10/test\", train=False, download=True, transform=transform)\n",
    "\n",
    "# using a 90-10 split of the data for training and validation\n",
    "# set to a fixed seed so that results will be reproduced\n",
    "data_train, data_val = torch.utils.data.random_split(data_train, [0.9, 0.1], generator=torch.Generator().manual_seed(31415))\n",
    "\n",
    "# create the dataloaders for each dataset. These will be used for training and getting accuracy of a model\n",
    "dataloader_train = torch.utils.data.DataLoader(data_train, batch_size=128, shuffle=False)\n",
    "dataloader_val = torch.utils.data.DataLoader(data_val, batch_size=128, shuffle=False)\n",
    "dataloader_test = torch.utils.data.DataLoader(data_test, batch_size=128, shuffle=False)\n",
    "\n",
    "print(np.shape(data_test.data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ResNet-56 model for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = resnet.resnet56()\n",
    "\n",
    "# load the model with the correct weights\n",
    "# must use DataParallel since the data was saved as a DataParallel\n",
    "torch.nn.DataParallel(model).load_state_dict(torch.load('pytorch_resnet_cifar10/pretrained_models/resnet56-4bfd9763.th', map_location=device)['state_dict'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias', 'weight']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_utils.prepare_model(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136\n"
     ]
    }
   ],
   "source": [
    "# this is not data snooping. This is just verifying that the already trained model was loaded in correctly. \n",
    "\n",
    "print(model_utils.get_accuracy(model, dataloader_test, device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning.global_mag_weight_prune(model, 0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Pruned Percentage and get the new accuracy without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899999529951491\n",
      "0.7044\n"
     ]
    }
   ],
   "source": [
    "print(model_utils.pruned_percentage(model, 'weight'))\n",
    "print(model_utils.get_accuracy(model, dataloader_val, device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=0.0001)\n",
    "\n",
    "for epoch in range(1):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    for (images, labels) in dataloader_train:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the model is still mostly pruned and test the accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899999529951491\n",
      "0.8895\n"
     ]
    }
   ],
   "source": [
    "print(model_utils.pruned_percentage(model, 'weight'))\n",
    "print(model_utils.get_accuracy(model, dataloader_test, device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.remove_pruning(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.002233248203993"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start  = time.perf_counter()\n",
    "time.sleep(2)\n",
    "stop = time.perf_counter()\n",
    "\n",
    "stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "692f3afc0acd1fc369913cd5a04d209b2475875d1d15a337870e8b7808ad8563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
